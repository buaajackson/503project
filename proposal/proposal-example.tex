\documentclass[11pt]{amsart}
\usepackage{geometry}
\geometry{letterpaper}
\usepackage[parfill]{parskip}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Project Proposal}
\author{Wenjing Yu, Peng Wan, Lingyu Deng, Zhen Lu}

\begin{document}
\maketitle
\section{Background}
Modern information retrieval becomes an important role in daily life. Many research topics
are based on this area and search engines are one of them. Many of us have built search engines 
before using tools like \emph{Apache Lucene}\footnote{For more details, see 
http://lucene.apache.org}. 

The technologies for search engines are well-developed by now. Also there are lots of tools providing frameworks to build search engines easily. 
For some commercial search engines, parallelism is widely used in data processing during the different steps to 
construct a search engine. For academic purposes, it would be interesting to utilize the parallel algorithms we learnt in the class
into build our own search engine. Through this project development, it would be helpful for us to expand the knowledge in 
search engine and deepen the understanding towards the different models and algorithms in the paralle programming area.

\section{Problem Description}
For modern search engines, there are 4 main parts, including crawling web pages, indexing documents, 
ranking and querying. 

Web crawler handles obtaining data from the web. Giving some starting URLs, a crawler downloads the
pages and parse the page to extract the URLs inside the page. 

The most common method for indexing is to represent the documents using vector space model. This part
mainly focuses on the representation and building an inverted index for documents.

When it comes to rank, PageRank is the most popular algorithm to measure the importance of a page. 

At last, when a query is given, we can use the inverted index and calculated PageRank for each page
to get the result matches the query best and then returns a ranked list to user as the final result.

\section{Proposed Work}
Based on the main parts of search enginesï¼Œ this project can be divided into 4 parts as well. Details
for each part will be described below.

\begin{itemize}
	\item {\bf Crawling:} implement a parallel web crawler for obtaining data from some seed URLs.
	\item {\bf Indexing:} use vector space model for document representation, then build the inverted
	document index for the dataset. 
	\item {\bf Ranking:} implement a parallel version for PageRank algorithm.
	\item {\bf Querying:} build the parallel query system to get the search result for a specific query.
\end{itemize}

The techniques we decide to use to implement this project is MapReduce. We will use Hadoop as the MapReduce
implementation. So the language would be JAVA.

The reason why we choose MapReduce is that MapReduce is an elegant framework for parallel programming. And
applying MapReduce would make this project more interesting to work with. 

The main focus for this project will be on Ranking algorithm and Querying method. Crawling and indexing part
does not have much dependent data for each single document, that would make this easy to implement and less
interesting. However, calculating PageRank and search the related document for a query requires many steps
and they share lots of data. For example, when calculating PageRank, we need to use the result from previous
iteration to calculation the value in current iteration. That requires more techniques to handle data 
dependency.

\end{document}
